<!DOCTYPE html><html><head><meta charset="UTF-8"><title> 🐘AWS EC2에서 Hadoop 구축 </title><meta name="viewport" content="width=device-width, user-scalable=no"><meta http-equiv="X-UA-Compatible" content="ie=edge"><meta property="og:title" content="🐘AWS EC2에서 Hadoop 구축"><meta property="og:image" content="https://user-images.githubusercontent.com/60086878/95056968-6fc5f100-0730-11eb-8359-b6f389b8c468.jpeg"><meta property="og:description" content="빅데이터 일등공신, 대용량 분산 파일 시스템"><meta name="twitter:title" content="🐘AWS EC2에서 Hadoop 구축"><meta name="twitter:image" content="https://user-images.githubusercontent.com/60086878/95056968-6fc5f100-0730-11eb-8359-b6f389b8c468.jpeg"><meta name="twitter:description" content="빅데이터 일등공신, 대용량 분산 파일 시스템"><meta name="twitter:card" content="summary_large_image"><meta name="robots" content="index,follow"><link rel="preload" href="/init.366dd74d.css" as="style"><link rel="preload" href="/article.e1e8064f.css" as="style"><link rel="canonical" href="https://inkkim.github.io/article/0.html"><link rel="shortcut icon" href="/favicon.a35c33cf.ico" type="image/x-icon"><link rel="stylesheet" href="/init.366dd74d.css"><link rel="stylesheet" href="/article.e1e8064f.css"><script async src="https://www.googletagmanager.com/gtag/js?id=UA-179600475-1"></script><script>function a(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],a("js",new Date),a("config","UA-179600475-1");</script></head><body> <header id="top-container" role="navigation"> </header> <main id="main-container"> <article id="article-container"> <h1 id="article-title"> 🐘AWS EC2에서 Hadoop 구축 </h1> <h2 id="article-subtitle"> 빅데이터 일등공신, 대용량 분산 파일 시스템 </h2> <time id="article-date"> 2020.10.18 </time> <section id="article-content-container"> <details><summary>Table of Contents</summary>
<p><div class="table-of-contents"><ul><li><a href="#%F0%9F%90%98-%ED%95%98%EB%91%A1(hadoop)%EC%9D%B4%EB%9E%80-%3F">🐘 하둡(Hadoop)이란 ?</a></li><li><a href="#%ED%95%B5%EC%8B%AC-%EC%BB%B4%ED%8F%AC%EB%84%8C%ED%8A%B8">핵심 컴포넌트</a><ul><li><a href="#%ED%95%98%EB%91%A1-%EB%B6%84%EC%82%B0-%ED%8C%8C%EC%9D%BC-%EC%8B%9C%EC%8A%A4%ED%85%9C(hdfs%2C-hadoop-distributed-file-system)">하둡 분산 파일 시스템(HDFS, Hadoop Distributed File System)</a></li><li><a href="#%EC%96%80(yarn%2C-yet-another-resource-negotiator)">얀(YARN, Yet Another Resource Negotiator)</a></li><li><a href="#%EB%A7%B5%EB%A6%AC%EB%93%80%EC%8A%A4(mapreduce)">맵리듀스(MapReduce)</a></li></ul></li><li><a href="#%EA%B5%AC%EC%B6%95-%EB%B0%A9%EB%B2%95">구축 방법</a><ul><li><a href="#aws-ec2-%EC%9D%B8%EC%8A%A4%ED%84%B4%EC%8A%A4-%EC%83%9D%EC%84%B1">AWS EC2 인스턴스 생성</a></li><li><a href="#%EB%A6%AC%EB%88%85%EC%8A%A4-%ED%99%98%EA%B2%BD%EC%84%A4%EC%A0%95">리눅스 환경설정</a></li><li><a href="#hadoop-%EC%84%A4%EC%B9%98">Hadoop 설치</a></li><li><a href="#%EC%9D%B4%EB%AF%B8%EC%A7%80-%EC%83%9D%EC%84%B1-%EB%B0%8F-%EB%B3%B5%EC%82%AC">이미지 생성 및 복사</a></li><li><a href="#hadoop-%EC%8B%A4%ED%96%89">Hadoop 실행</a></li></ul></li><li><a href="#%EC%B0%B8%EA%B3%A0">참고</a></li></ul></div></p>
</details>
<h1 id="%F0%9F%90%98-%ED%95%98%EB%91%A1(hadoop)%EC%9D%B4%EB%9E%80-%3F">🐘 하둡(Hadoop)이란 ?</h1>
<ul>
<li>대규모 검색 색인을 구축하기 위해 Java로 개발된 오픈 소스 분산 컴퓨팅 플랫폼</li>
</ul>
<p><img src="https://user-images.githubusercontent.com/60086878/96373727-59e11300-11a9-11eb-8e90-87e63b3c40b2.jpg" alt="Hadoop Logo"></p>
<p>하둡의 로고의 코끼리는 개발자 더그 커팅이 자신의 아이가 가지고 놀던 장난감 코끼리의 이름을 따서 하둡이라는 이름을 지었다고 한다.f(개발자의 네이밍 세계는 생각보다 단순하다.)</p>
<h1 id="%ED%95%B5%EC%8B%AC-%EC%BB%B4%ED%8F%AC%EB%84%8C%ED%8A%B8">핵심 컴포넌트</h1>
<h2 id="%ED%95%98%EB%91%A1-%EB%B6%84%EC%82%B0-%ED%8C%8C%EC%9D%BC-%EC%8B%9C%EC%8A%A4%ED%85%9C(hdfs%2C-hadoop-distributed-file-system)">하둡 분산 파일 시스템(HDFS, Hadoop Distributed File System)</h2>
<p>앞서 언급했듯이 하둡은 확장성과 장애 허용성을 가진 분산 파일 시스템이다. 대규모 데이터셋 분석이라는 하둡의 원래 용도에 맞게, HDFS는 일반적으로 상당히 긴 순차 접근(Sequential Access)방식을 통해 디스크에 불변 데이터를 저장하는데 최적화돼 있다. 그러므로 HDFS는 하둡 스택 내 다른 컴포넌트를 지원하는 핵심 기술이다.</p>
<ul>
<li>데이터를 설정 가능한 크기의 블록으로 나눠 저장 (기본값은 128MB)</li>
<li>데이터 회복성 및 병렬 처리를 위해 여러 대의 서버에 각 블록의 복제본(Replica) 저장</li>
<li>마스터 서버에서 실행되는 네임노드(Namenode) 프로세스가 파일이 어느 복제본에 속하는지에 대한 정보와 파일과 블록 사이의 매핑 정보, 파일 이름, 권한, 속성, 복제 계수(Replication Factor)등 파일 자체의 메타 데이터를 모두 관리</li>
<li>파일의 일부분 수정 미지원으로 불변성을 보장하여 수평적 확장성과 데이터 회복력을 비교적 단순한 방법으로 획득</li>
</ul>
<h2 id="%EC%96%80(yarn%2C-yet-another-resource-negotiator)">얀(YARN, Yet Another Resource Negotiator)</h2>
<p>하둡의 클러스터 관리 시스템으로 가장 효율적인 방법으로 계산, 리소스를 할당하고 사용자 애플리케이션을 스케쥴링하는 시스템이다. 스케쥴링과 리소스 관리로 데이터 지역성을 극대화하고, 계산량이 많은 애플리케이션이 리소스를 독점하지 않게 제어 및 교체 가능한 스케쥴링 시스템을 지원한다. 사용자당 리소스 제한이나 작업 대기열당 리소스 할당량 등 공용 리소스 시스템의 스케쥴링에 필요한 기본적인 환경 설정을 스케쥴러에 입력할 수 있다.</p>
<p><img src="https://user-images.githubusercontent.com/60086878/96365911-08bc2980-117f-11eb-95ac-d37e775255ad.png" alt="Hadoop Logo"></p>
<ul>
<li>
<p>구성</p>
<ul>
<li>Resource Manager라고 불리는 마스터 노드
<ul>
<li>클러스터 전체의 계산 리소스를 관리하고, 클라이언트가 요구한 리소스를 Node Manager로부터 확보하도록 스케쥴링함</li>
<li>요청된 Executor 개수와 CPU 코어의 수, 메모리 양에 따라 Executor를 하나 이상의 Node Manager로부터 확보하는 역할을 담당</li>
</ul>
</li>
<li>Node Manager라고 하는 여러 개의 워커 노드
<ul>
<li>자신이 설치된 노드의 계산 리소스만을 관리</li>
</ul>
</li>
</ul>
</li>
<li>
<p>클러스터의 리소스를 컨테이너로 분할하고, 기본적으로 할당되는 CPU 코어 수와 메모리 용량으로 정의되며 출가 리소스를 포함할 수도 있음</p>
</li>
<li>
<p>실행중인 컨테이너들을 모니터링하면서 컨테이너가 리소스의 최대 할당량을 초과하지 않게 억제</p>
</li>
<li>
<p>클러스터의 리소스를 컨테이너로 관리함으로써 분산 시스템을 전체적으로 원활하게 운영하고, 클러스터의 리소스를 다수 애플리케이션에 공평한 방식으로 공유</p>
</li>
<li>
<p>컨테이너를 비공개로 설정할 수도 있고, 사용자가 요청한 작업을 적절한 시점에 시작할 수도 있음</p>
</li>
</ul>
<h2 id="%EB%A7%B5%EB%A6%AC%EB%93%80%EC%8A%A4(mapreduce)">맵리듀스(MapReduce)</h2>
<ul>
<li>2004년 구글에서 대용량 데이터를 분산처리하기 위해 발표한 대용량 분산 처리 프레임워크</li>
<li>테라바이트 또는 페타바이트 이상의 대용량 데이터를 저렴한 x86 서버를 클러스터링해 분산 처리</li>
<li>데이터를 처리하는 기본 단위는 매퍼(Mapper)와 리듀스(Reduce)</li>
<li>맵(Map)은 산재된 데이터를 키와 벨류 형태로 연관성이 있는 데이터로 묶는 작업</li>
<li>리듀스(Reduce)는 맵 작업 결과에서 중복 데이터를 제거한 후 원하는 데이터를 추출하는 작업을 수행</li>
</ul>
<h1 id="%EA%B5%AC%EC%B6%95-%EB%B0%A9%EB%B2%95">구축 방법</h1>
<ul>
<li>구축 환경
<ul>
<li>MacOS(Catalina 10.15.5)</li>
<li>AWS EC2
<ul>
<li>t2.small(3EA)</li>
</ul>
</li>
<li>Red Hat Enterprise Linux 8</li>
<li>SSD 30GB</li>
</ul>
</li>
</ul>
<h2 id="aws-ec2-%EC%9D%B8%EC%8A%A4%ED%84%B4%EC%8A%A4-%EC%83%9D%EC%84%B1">AWS EC2 인스턴스 생성</h2>
<ol>
<li>
<p>AWS에서 계정을 생성하고 로그인 한 후, AWS Management Console - 컴퓨팅 - EC2에 접근한다.</p>
</li>
<li>
<p>인스턴스 시작을 눌러, 다음 순서대로 인스턴스를 생성한다.</p>
<ul>
<li>AMI 선택</li>
</ul>
<p><img src="https://user-images.githubusercontent.com/60086878/96366595-74a09100-1183-11eb-808b-88dfd2f21adb.png" alt="Amazon Machine Image">
Red Hat Enterprise Linux 8</p>
<ul>
<li>인스턴스 유형 선택</li>
</ul>
<p><img src="https://user-images.githubusercontent.com/60086878/96366700-2e97fd00-1184-11eb-8e1c-7e5d011c7a98.png" alt="AWS On-Demand Pricing">
- 요금이 t2.micro의 겨우 2배 수준인 t2.small
- AWS의 살인적인 요금제에 프리티어 과금을 피하기 위하여 인스턴스 유형은 프리티어급보다 한 단계 상위버전인 t2.small로 진행</p>
<ul>
<li>
<p>인스턴스 구성
1개로 구성하여 하둡에 필요한 설정을 모두 마친 후 이미지를 생성하여 나머지 2개를 만들 예정</p>
</li>
<li>
<p>스토리지 추가
30 GB</p>
</li>
<li>
<p>검토</p>
<ul>
<li>
<p>AWS EC2를 처음 이용할 경우, 새 키 페어 생성으로 키 페어 이름을 입력한 후 키 페어 다운로드</p>
</li>
<li>
<p>기존 유저의 경우, 기존 키 페어 선택 후 선택한 키 파일에 엑세스 가능 여부 체크</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>인스턴스 접속</p>
</li>
</ol>
<p><img src="https://user-images.githubusercontent.com/60086878/96367212-5f2d6600-1187-11eb-8267-241a050a9571.png" alt="IPv4 Public IP"></p>
<ul>
<li>해당 인스턴스의 Public IP를 복사하고, 터미널에서 ssh 명령어를 통해 접속한다.</li>
</ul>
<pre class="hljs"><code>$ ssh -i ./YOUR_KEY.pem ec2-user@PUBLIC_IP
</code></pre>
<p><img src="https://user-images.githubusercontent.com/60086878/96367234-7d936180-1187-11eb-8583-473b718bcc44.png" alt="SSH Access"></p>
<h2 id="%EB%A6%AC%EB%88%85%EC%8A%A4-%ED%99%98%EA%B2%BD%EC%84%A4%EC%A0%95">리눅스 환경설정</h2>
<ol>
<li>SELINUX 끄기</li>
</ol>
<p>원활한 설치를 위해 Red Hat 보안 요소인 SELINUX를 끄고 진행</p>
<ul>
<li>etc 파일 수정을 위해 sudo 명령어로 config 파일 열기</li>
</ul>
<pre class="hljs"><code>$ sudo vi /etc/selinux/config
</code></pre>
<ul>
<li>SELINUX disabled</li>
</ul>
<pre class="hljs"><code>SELINUX=disabled
</code></pre>
<ul>
<li>변경사항 적용을 위해 재부팅</li>
</ul>
<pre class="hljs"><code>$ sudo reboot
</code></pre>
<ol start="2">
<li>보안상 새로운 계정을 생성</li>
</ol>
<ul>
<li>hadoop 이름으로 새로운 계정 생성</li>
</ul>
<pre class="hljs"><code>$ useradd hadoop
</code></pre>
<ul>
<li>비밀번호 설정</li>
</ul>
<pre class="hljs"><code>$ passwd hadoop
</code></pre>
<ol start="3">
<li>hadoop 계정에 sudo 권한 부여</li>
</ol>
<ul>
<li>etc 파일 수정을 위해 sudo 명령어와 쓰기 권한없이 바로 편집할 수 있는 visud 명령어를 통해 sudoers파일 열기</li>
</ul>
<pre class="hljs"><code>$ sudo visudo /etc/sudoers
</code></pre>
<ul>
<li>계정권한 부여 명령 추가</li>
</ul>
<pre class="hljs"><code>hadoop  ALL=(ALL)   ALL
</code></pre>
<p><img src="https://user-images.githubusercontent.com/60086878/96367971-e67cd880-118b-11eb-80ed-635a50aab6ef.png" alt="Add Permission"></p>
<ol start="4">
<li>SSH Key-based 인증 설정</li>
</ol>
<p>공개키를 등록하여 각 인스턴스끼리 비밀번호 없이 지속적인 통신을 가능하게 함</p>
<ul>
<li>hadoop 계정 로그인</li>
</ul>
<pre class="hljs"><code>$ su hadoop
</code></pre>
<ul>
<li>SSH Key 생성 (명령어 실행 후 엔터)</li>
</ul>
<pre class="hljs"><code>$ ssh-keygen -t rsa
</code></pre>
<ul>
<li>authorized_keys파일에 공개키 추가</li>
</ul>
<pre class="hljs"><code>$ cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh authorized_keys
</code></pre>
<ul>
<li>authorized_keys 권한 부여</li>
</ul>
<pre class="hljs"><code>$ chmod 640 ~/.ssh/authorized_keys
</code></pre>
<ul>
<li>ssh 접속 확인</li>
</ul>
<pre class="hljs"><code>$ ssh localhost
</code></pre>
<h2 id="hadoop-%EC%84%A4%EC%B9%98">Hadoop 설치</h2>
<ol>
<li>Java 설치</li>
</ol>
<p>Hadoop은 Java로 쓰여진 오픈 소스이므로 사전에 Java 설치 필수이다. 따라서 Java 버전에 영향을 많이 받으므로, Hadoop 3.2.1 버전과 호환되는 java-1.8.0-openjdk 버전 설치한다.</p>
<ul>
<li>Java 설치</li>
</ul>
<pre class="hljs"><code>$ sudo dnf install java-1.8.0-openjdk ant -y
</code></pre>
<ul>
<li>Java 명령어로 설치여부 확인</li>
</ul>
<pre class="hljs"><code>$ java -version
</code></pre>
<ol start="2">
<li>Hadoop 설치</li>
</ol>
<p><a href="https://downloads.apache.org/hadoop/common/hadoop-3.2.1/hadoop-3.2.1.tar.gz">Hadoop 3.2.1</a> 해당 링크를 복사하여 설치</p>
<ul>
<li>웹 파일 다운로드 패키지 다운로드</li>
</ul>
<pre class="hljs"><code>$ sudo yum install wget
</code></pre>
<ul>
<li>Hadoop 설치</li>
</ul>
<pre class="hljs"><code>$ cd ~
$ sudo wget https://downloads.apache.org/hadoop/common/hadoop-3.2.1/hadoop-3.2.1.tar.gz
$ tar -xvzf hadoop-3.2.1.tar.gz
</code></pre>
<ul>
<li>폴더명 변경</li>
</ul>
<pre class="hljs"><code>$ mv hadoop-3.2.1 hadoop
</code></pre>
<ul>
<li>환경변수 설정</li>
</ul>
<pre class="hljs"><code>$ vi ~/.bashrc
</code></pre>
<ul>
<li>환경변수 내용 추가</li>
</ul>
<p><a href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/ClusterSetup.html">Hadoop Cluster 설정 관련 메뉴얼</a></p>
<pre class="hljs"><code>export JAVA_HOME=/usr/lib/jvm/jre-1.8.0-openjdk-1.8.0.265.b01-0.el8_2.x86_64
export HADOOP_HOME=/home/hadoop/hadoop
export HADOOP_INSTALL=$HADOOP_HOME
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export HADOOP_YARN_HOME=$HADOOP_HOME
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin
export HADOOP_OPTS=&quot;-Djava.library.path=$HADOOP_HOME/lib/native&quot;
</code></pre>
<p>JAVA_HOME은 /usr/lib/jvm/ 밑에 폴더명으로 설정(다운로드 시기에 따라 빌드 버전이 다를 수 있음)</p>
<ul>
<li>하둡 환경파일 수정</li>
</ul>
<pre class="hljs"><code>$ cd ~/hadoop/etc/hadoop
</code></pre>
<ul>
<li>workers ()</li>
</ul>
<pre class="hljs"><code>datanode1
datanode2
</code></pre>
<ul>
<li>core-site.xml</li>
</ul>
<pre class="hljs"><code>&lt;configuration&gt;
 &lt;property&gt;
  &lt;name&gt;fs.defaultFS&lt;/name&gt;
   &lt;value&gt;hdfs://namenode:8020/&lt;/value&gt;
 &lt;/property&gt;
 &lt;property&gt;
  &lt;name&gt;io.file.buffer.size&lt;/name&gt;
   &lt;value&gt;131072&lt;/value&gt;
 &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>
<ul>
<li>hdfs-site.xml</li>
</ul>
<pre class="hljs"><code>&lt;configuration&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.replication&lt;/name&gt;
		&lt;value&gt;1&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.namenode.http-address&lt;/name&gt;
		&lt;value&gt;namenode:50070&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
		&lt;value&gt;secondnode:50090&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.datanode.http-address&lt;/name&gt;
		&lt;value&gt;0.0.0.0:50010&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
		&lt;value&gt;file:///home/hadoop/hadoop/data/name1,file:///home/hadoop/hadoop/data/name2&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
		&lt;value&gt;file:///home/hadoop/hadoop/data&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.namenode.checkpoint.dir&lt;/name&gt;
		&lt;value&gt;file:///home/hadoop/hadoop/data/namesecondary&lt;/value&gt;
	&lt;/property&gt;
&lt;/configuration&gt;
</code></pre>
<ul>
<li>mapred-site.xml</li>
</ul>
<pre class="hljs"><code>&lt;configuration&gt;
        &lt;property&gt;
                &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
                &lt;value&gt;yarn&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
                &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;
                &lt;value&gt;namenode:10020&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
                &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;
                &lt;value&gt;namenode:19888&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
                &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt;
                &lt;value&gt;HADOOP_MAPRED_HOME=${HADOOP_HOME}&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
                &lt;name&gt;mapreduce.map.env&lt;/name&gt;
                &lt;value&gt;HADOOP_MAPRED_HOME=${HADOOP_HOME}&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
                &lt;name&gt;mapreduce.reduce.env&lt;/name&gt;
                &lt;value&gt;HADOOP_MAPRED_HOME=${HADOOP_HOME}&lt;/value&gt;
        &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>
<ul>
<li>yarn-site.xml</li>
</ul>
<pre class="hljs"><code>&lt;configuration&gt;

&lt;!-- Site specific YARN configuration properties --&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
		&lt;value&gt;secondnode&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.nodemanager.local-dirs&lt;/name&gt;
		&lt;value&gt;/home/hadoop/hadoop/data/nm&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
		&lt;value&gt;mapreduce_shuffle&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;yarn.nodemanager.resource.cpu-vcores&lt;/name&gt;
		&lt;value&gt;2&lt;/value&gt;
	&lt;/property&gt;
&lt;/configuration&gt;
</code></pre>
<ul>
<li>hdfs 저장을 위한 디렉토리 생성</li>
</ul>
<pre class="hljs"><code>$ cd hadoop
$ mkdir data
</code></pre>
<ul>
<li>종료</li>
</ul>
<pre class="hljs"><code>$ sudo shutdown -h now
</code></pre>
<h2 id="%EC%9D%B4%EB%AF%B8%EC%A7%80-%EC%83%9D%EC%84%B1-%EB%B0%8F-%EB%B3%B5%EC%82%AC">이미지 생성 및 복사</h2>
<ol>
<li>이미지 복사</li>
</ol>
<ul>
<li>인스턴스 목록에서 해당 인스턴스 선택 후 복사
<img src="https://user-images.githubusercontent.com/60086878/96369153-55a9fb00-1193-11eb-865d-5a4c82677af9.png" alt="Create AMI"></li>
</ul>
<ol start="2">
<li>AMI 생성</li>
</ol>
<ul>
<li>
<p>AMI 목록에서 해당 이미지 생성 (나머지 구성은 동일하게 하되, 인스턴스 구성은 2개로 진행)</p>
</li>
<li>
<p>인스턴스 목록에서 각 인스턴스를 구분하기 쉽게, 인스턴스 이름을 각각 Client, Namenode, Secondnode로 수정
<img src="https://user-images.githubusercontent.com/60086878/96369527-7ecb8b00-1195-11eb-9a89-483cc5396bac.png" alt="Set Name"></p>
</li>
<li>
<p>이전과 동일한 방법으로 3개의 터미널에서 각각의 인스턴스에 접속 (인스턴스는 재부팅 후 Public IP가 재할당되므로 재확인 후 접속)</p>
</li>
</ul>
<ol start="3">
<li>hostname 설정</li>
</ol>
<ul>
<li>각각의 인스턴스에서 진행</li>
</ul>
<pre class="hljs"><code>$ sudo hostnamectl set-hostname client
$ sudo hostnamectl set-hostname namenode
$ sudo hostnamectl set-hostname secondnode
</code></pre>
<ol start="4">
<li>각각의 인스턴스 연결</li>
</ol>
<ul>
<li>hosts 파일 열기</li>
</ul>
<pre class="hljs"><code>$ sudo vi /etc/hosts
</code></pre>
<ul>
<li>각각의 Private IP 연동 (172.x.x.x)</li>
</ul>
<pre class="hljs"><code>127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
172.31.28.51    client
172.31.18.187   namenode
172.31.18.187   datanode1
172.31.20.195   secondnode
172.31.20.195   datanode2
</code></pre>
<p><img src="https://user-images.githubusercontent.com/60086878/96369633-2943ae00-1196-11eb-951f-b45c8d91a16f.png" alt="Private IP"></p>
<ul>
<li>SSH 접근 확인 (hadoop 계정에서 실행)</li>
</ul>
<pre class="hljs"><code>$ ssh client
$ ssh secondnode
$ ssh namenode
</code></pre>
<p>모두 이상없이 연결된다면 각각의 인스턴스가 서로 인증없이 통신할 수 있는 상태를 의미</p>
<h2 id="hadoop-%EC%8B%A4%ED%96%89">Hadoop 실행</h2>
<ol>
<li>Hadoop 구동</li>
</ol>
<ul>
<li>hdfs 파일 포맷</li>
</ul>
<pre class="hljs"><code>$ hadoop namenode -format 
</code></pre>
<ul>
<li>dfs(namenode) 시작</li>
</ul>
<pre class="hljs"><code>$ start-dfs.sh
$ jps
$ ssh secondnode
$ jps
</code></pre>
<p>namenode에서는 jps 명령어 시 DataNode, NameNode가 실행</p>
<p>secondnode에서는 jps 명령어 시 DataNode, SecondaryNameNode가 실행</p>
<ul>
<li>yarn(secondnode) 시작</li>
</ul>
<pre class="hljs"><code>$ start-yarn.sh
$ jps
</code></pre>
<p>secondnode에서 jps 명령어 시 추가로 ResourceManager, NodeManager가 실행</p>
<ol start="2">
<li>Hadoop 모니터링
외부에서 인스턴스에 접속할 수 있도록 방화벽 설정을 통해 특정 IP와 포트를 설정하는 작업이 필요</li>
</ol>
<ul>
<li>
<p>내 IP 확인
<a href="https://www.findip.kr">내 IP 주소 확인</a></p>
</li>
<li>
<p>보안그룹 설정 접근
<img src="https://user-images.githubusercontent.com/60086878/96371729-2baa0600-119e-11eb-8347-cc7c3548c1fb.png" alt="Security Group"></p>
</li>
<li>
<p>인스턴스의 보안그룹 탭으로 접근하여 각 인스턴스에 해당하는 보안그룹의 인바운드 규칙 편집
<img src="https://user-images.githubusercontent.com/60086878/96371898-12ee2000-119f-11eb-8782-ff4388e21825.png" alt="Setting Security Group"></p>
</li>
</ul>
<p>소스는 각자 본인 IP 주소/32(eg; 111.222.333.4/32)</p>
<ul>
<li>namenode Public IP:50070</li>
<li>secondnode Public IP:8088
<img src="https://user-images.githubusercontent.com/60086878/96372012-d53dc700-119f-11eb-8dff-a1dd1c25c075.png" alt="Manage Page"></li>
</ul>
<h1 id="%EC%B0%B8%EA%B3%A0">참고</h1>
<ul>
<li>엔터프라이즈 데이터 플랫폼 구축 (책만)</li>
<li><a href="http://www.dbguide.net/db.db?cmd=view&amp;boardUid=187336&amp;boardConfigUid=9&amp;categoryUid=1459&amp;boardIdx=158&amp;boardStep=1">데이터실무 기술 가이드 &gt; 데이터 처리</a> (DBGuide)</li>
<li><a href="https://tecadmin.net/install-hadoop-centos-8/">How To Install and Configure Hadoop on CentOS/RHEL 8</a></li>
</ul> </section> <section id="article-navigation"> <div class="article-navigation-item article-navigation-next"> <a href="/article/6.html"> <div class="article-navigation-arrow article-navigation-next">＜</div> <div class="article-navigation-content article-navigation-next"> <p class="article-navigation-title">AWS EKS 클러스터에 Kubeflow 설치하기</p> <p class="article-navigation-subtitle">ML Toolkit for Kubernetes</p> </div> </a> </div> </section> <section id="article-social-container"> <div id="fb-like" class="fb-like" data-href="https://inkkim.github.io/article/0.html" data-layout="button_count" data-action="like" data-size="small" data-show-faces="true" data-share="true"></div> <a href="https://twitter.com/share" class="twitter-share-button" data-show-count="true"></a> </section> <section id="article-comments"> <script async src="https://utteranc.es/client.js" repo="inkkim/inkkim.github.io-comments" issue-term="pathname" theme="github-light" crossorigin="anonymous">
	</script> </section> <section id="article-list-button-container"> <a href="/articles.html"> <div id="article-list-button">📚</div> </a> </section> </article> </main> <div id="fb-root"></div> <script async defer crossorigin="anonymous" src="https://connect.facebook.net/en_US/sdk.js#xfbml=1&version=v3.0"></script> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> <script defer src="/init.ddb7c0df.js"></script>
</body></html>