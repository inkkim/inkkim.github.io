---
id: 0
title: "ğŸ˜AWS EC2ì—ì„œ Hadoop êµ¬ì¶•"
subtitle: "ë¹…ë°ì´í„° ì¼ë“±ê³µì‹ , ëŒ€ìš©ëŸ‰ ë¶„ì‚° íŒŒì¼ ì‹œìŠ¤í…œ"
date: "2020.10.18"
tags: "ë¹…ë°ì´í„°, ë¶„ì‚°ì²˜ë¦¬, ì¸í”„ë¼"
---

# ğŸ˜ í•˜ë‘¡(Hadoop)ì´ë€ ? 
- ëŒ€ê·œëª¨ ê²€ìƒ‰ ìƒ‰ì¸ì„ êµ¬ì¶•í•˜ê¸° ìœ„í•´ Javaë¡œ ê°œë°œëœ ì˜¤í”ˆ ì†ŒìŠ¤ ë¶„ì‚° ì»´í“¨íŒ… í”Œë«í¼

![Hadoop Logo](https://user-images.githubusercontent.com/60086878/96373727-59e11300-11a9-11eb-8e90-87e63b3c40b2.jpg)

 í•˜ë‘¡ì˜ ë¡œê³ ì˜ ì½”ë¼ë¦¬ëŠ” ê°œë°œì ë”ê·¸ ì»¤íŒ…ì´ ìì‹ ì˜ ì•„ì´ê°€ ê°€ì§€ê³  ë†€ë˜ ì¥ë‚œê° ì½”ë¼ë¦¬ì˜ ì´ë¦„ì„ ë”°ì„œ í•˜ë‘¡ì´ë¼ëŠ” ì´ë¦„ì„ ì§€ì—ˆë‹¤ê³  í•œë‹¤.f(ê°œë°œìì˜ ë„¤ì´ë° ì„¸ê³„ëŠ” ìƒê°ë³´ë‹¤ ë‹¨ìˆœí•˜ë‹¤.)

# í•µì‹¬ ì»´í¬ë„ŒíŠ¸

## í•˜ë‘¡ ë¶„ì‚° íŒŒì¼ ì‹œìŠ¤í…œ(HDFS, Hadoop Distributed File System)
 ì•ì„œ ì–¸ê¸‰í–ˆë“¯ì´ í•˜ë‘¡ì€ í™•ì¥ì„±ê³¼ ì¥ì•  í—ˆìš©ì„±ì„ ê°€ì§„ ë¶„ì‚° íŒŒì¼ ì‹œìŠ¤í…œì´ë‹¤. ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ ë¶„ì„ì´ë¼ëŠ” í•˜ë‘¡ì˜ ì›ë˜ ìš©ë„ì— ë§ê²Œ, HDFSëŠ” ì¼ë°˜ì ìœ¼ë¡œ ìƒë‹¹íˆ ê¸´ ìˆœì°¨ ì ‘ê·¼(Sequential Access)ë°©ì‹ì„ í†µí•´ ë””ìŠ¤í¬ì— ë¶ˆë³€ ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ”ë° ìµœì í™”ë¼ ìˆë‹¤. ê·¸ëŸ¬ë¯€ë¡œ HDFSëŠ” í•˜ë‘¡ ìŠ¤íƒ ë‚´ ë‹¤ë¥¸ ì»´í¬ë„ŒíŠ¸ë¥¼ ì§€ì›í•˜ëŠ” í•µì‹¬ ê¸°ìˆ ì´ë‹¤.

- ë°ì´í„°ë¥¼ ì„¤ì • ê°€ëŠ¥í•œ í¬ê¸°ì˜ ë¸”ë¡ìœ¼ë¡œ ë‚˜ëˆ  ì €ì¥ (ê¸°ë³¸ê°’ì€ 128MB)
- ë°ì´í„° íšŒë³µì„± ë° ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•´ ì—¬ëŸ¬ ëŒ€ì˜ ì„œë²„ì— ê° ë¸”ë¡ì˜ ë³µì œë³¸(Replica) ì €ì¥
- ë§ˆìŠ¤í„° ì„œë²„ì—ì„œ ì‹¤í–‰ë˜ëŠ” ë„¤ì„ë…¸ë“œ(Namenode) í”„ë¡œì„¸ìŠ¤ê°€ íŒŒì¼ì´ ì–´ëŠ ë³µì œë³¸ì— ì†í•˜ëŠ”ì§€ì— ëŒ€í•œ ì •ë³´ì™€ íŒŒì¼ê³¼ ë¸”ë¡ ì‚¬ì´ì˜ ë§¤í•‘ ì •ë³´, íŒŒì¼ ì´ë¦„, ê¶Œí•œ, ì†ì„±, ë³µì œ ê³„ìˆ˜(Replication Factor)ë“± íŒŒì¼ ìì²´ì˜ ë©”íƒ€ ë°ì´í„°ë¥¼ ëª¨ë‘ ê´€ë¦¬
- íŒŒì¼ì˜ ì¼ë¶€ë¶„ ìˆ˜ì • ë¯¸ì§€ì›ìœ¼ë¡œ ë¶ˆë³€ì„±ì„ ë³´ì¥í•˜ì—¬ ìˆ˜í‰ì  í™•ì¥ì„±ê³¼ ë°ì´í„° íšŒë³µë ¥ì„ ë¹„êµì  ë‹¨ìˆœí•œ ë°©ë²•ìœ¼ë¡œ íšë“

## ì–€(YARN, Yet Another Resource Negotiator)
 í•˜ë‘¡ì˜ í´ëŸ¬ìŠ¤í„° ê´€ë¦¬ ì‹œìŠ¤í…œìœ¼ë¡œ ê°€ì¥ íš¨ìœ¨ì ì¸ ë°©ë²•ìœ¼ë¡œ ê³„ì‚°, ë¦¬ì†ŒìŠ¤ë¥¼ í• ë‹¹í•˜ê³  ì‚¬ìš©ì ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìŠ¤ì¼€ì¥´ë§í•˜ëŠ” ì‹œìŠ¤í…œì´ë‹¤. ìŠ¤ì¼€ì¥´ë§ê³¼ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ë¡œ ë°ì´í„° ì§€ì—­ì„±ì„ ê·¹ëŒ€í™”í•˜ê³ , ê³„ì‚°ëŸ‰ì´ ë§ì€ ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ë¦¬ì†ŒìŠ¤ë¥¼ ë…ì í•˜ì§€ ì•Šê²Œ ì œì–´ ë° êµì²´ ê°€ëŠ¥í•œ ìŠ¤ì¼€ì¥´ë§ ì‹œìŠ¤í…œì„ ì§€ì›í•œë‹¤. ì‚¬ìš©ìë‹¹ ë¦¬ì†ŒìŠ¤ ì œí•œì´ë‚˜ ì‘ì—… ëŒ€ê¸°ì—´ë‹¹ ë¦¬ì†ŒìŠ¤ í• ë‹¹ëŸ‰ ë“± ê³µìš© ë¦¬ì†ŒìŠ¤ ì‹œìŠ¤í…œì˜ ìŠ¤ì¼€ì¥´ë§ì— í•„ìš”í•œ ê¸°ë³¸ì ì¸ í™˜ê²½ ì„¤ì •ì„ ìŠ¤ì¼€ì¥´ëŸ¬ì— ì…ë ¥í•  ìˆ˜ ìˆë‹¤.

 ![Hadoop Logo](https://user-images.githubusercontent.com/60086878/96365911-08bc2980-117f-11eb-95ac-d37e775255ad.png)
 
- êµ¬ì„± 
    - Resource Managerë¼ê³  ë¶ˆë¦¬ëŠ” ë§ˆìŠ¤í„° ë…¸ë“œ
        - í´ëŸ¬ìŠ¤í„° ì „ì²´ì˜ ê³„ì‚° ë¦¬ì†ŒìŠ¤ë¥¼ ê´€ë¦¬í•˜ê³ , í´ë¼ì´ì–¸íŠ¸ê°€ ìš”êµ¬í•œ ë¦¬ì†ŒìŠ¤ë¥¼ Node Managerë¡œë¶€í„° í™•ë³´í•˜ë„ë¡ ìŠ¤ì¼€ì¥´ë§í•¨
        - ìš”ì²­ëœ Executor ê°œìˆ˜ì™€ CPU ì½”ì–´ì˜ ìˆ˜, ë©”ëª¨ë¦¬ ì–‘ì— ë”°ë¼ Executorë¥¼ í•˜ë‚˜ ì´ìƒì˜ Node Managerë¡œë¶€í„° í™•ë³´í•˜ëŠ” ì—­í• ì„ ë‹´ë‹¹
    - Node Managerë¼ê³  í•˜ëŠ” ì—¬ëŸ¬ ê°œì˜ ì›Œì»¤ ë…¸ë“œ
        - ìì‹ ì´ ì„¤ì¹˜ëœ ë…¸ë“œì˜ ê³„ì‚° ë¦¬ì†ŒìŠ¤ë§Œì„ ê´€ë¦¬

- í´ëŸ¬ìŠ¤í„°ì˜ ë¦¬ì†ŒìŠ¤ë¥¼ ì»¨í…Œì´ë„ˆë¡œ ë¶„í• í•˜ê³ , ê¸°ë³¸ì ìœ¼ë¡œ í• ë‹¹ë˜ëŠ” CPU ì½”ì–´ ìˆ˜ì™€ ë©”ëª¨ë¦¬ ìš©ëŸ‰ìœ¼ë¡œ ì •ì˜ë˜ë©° ì¶œê°€ ë¦¬ì†ŒìŠ¤ë¥¼ í¬í•¨í•  ìˆ˜ë„ ìˆìŒ
- ì‹¤í–‰ì¤‘ì¸ ì»¨í…Œì´ë„ˆë“¤ì„ ëª¨ë‹ˆí„°ë§í•˜ë©´ì„œ ì»¨í…Œì´ë„ˆê°€ ë¦¬ì†ŒìŠ¤ì˜ ìµœëŒ€ í• ë‹¹ëŸ‰ì„ ì´ˆê³¼í•˜ì§€ ì•Šê²Œ ì–µì œ
- í´ëŸ¬ìŠ¤í„°ì˜ ë¦¬ì†ŒìŠ¤ë¥¼ ì»¨í…Œì´ë„ˆë¡œ ê´€ë¦¬í•¨ìœ¼ë¡œì¨ ë¶„ì‚° ì‹œìŠ¤í…œì„ ì „ì²´ì ìœ¼ë¡œ ì›í™œí•˜ê²Œ ìš´ì˜í•˜ê³ , í´ëŸ¬ìŠ¤í„°ì˜ ë¦¬ì†ŒìŠ¤ë¥¼ ë‹¤ìˆ˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì— ê³µí‰í•œ ë°©ì‹ìœ¼ë¡œ ê³µìœ 
- ì»¨í…Œì´ë„ˆë¥¼ ë¹„ê³µê°œë¡œ ì„¤ì •í•  ìˆ˜ë„ ìˆê³ , ì‚¬ìš©ìê°€ ìš”ì²­í•œ ì‘ì—…ì„ ì ì ˆí•œ ì‹œì ì— ì‹œì‘í•  ìˆ˜ë„ ìˆìŒ

## ë§µë¦¬ë“€ìŠ¤(MapReduce)
- 2004ë…„ êµ¬ê¸€ì—ì„œ ëŒ€ìš©ëŸ‰ ë°ì´í„°ë¥¼ ë¶„ì‚°ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ë°œí‘œí•œ ëŒ€ìš©ëŸ‰ ë¶„ì‚° ì²˜ë¦¬ í”„ë ˆì„ì›Œí¬
- í…Œë¼ë°”ì´íŠ¸ ë˜ëŠ” í˜íƒ€ë°”ì´íŠ¸ ì´ìƒì˜ ëŒ€ìš©ëŸ‰ ë°ì´í„°ë¥¼ ì €ë ´í•œ x86 ì„œë²„ë¥¼ í´ëŸ¬ìŠ¤í„°ë§í•´ ë¶„ì‚° ì²˜ë¦¬
- ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ê¸°ë³¸ ë‹¨ìœ„ëŠ” ë§¤í¼(Mapper)ì™€ ë¦¬ë“€ìŠ¤(Reduce)
- ë§µ(Map)ì€ ì‚°ì¬ëœ ë°ì´í„°ë¥¼ í‚¤ì™€ ë²¨ë¥˜ í˜•íƒœë¡œ ì—°ê´€ì„±ì´ ìˆëŠ” ë°ì´í„°ë¡œ ë¬¶ëŠ” ì‘ì—…
- ë¦¬ë“€ìŠ¤(Reduce)ëŠ” ë§µ ì‘ì—… ê²°ê³¼ì—ì„œ ì¤‘ë³µ ë°ì´í„°ë¥¼ ì œê±°í•œ í›„ ì›í•˜ëŠ” ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ëŠ” ì‘ì—…ì„ ìˆ˜í–‰

# êµ¬ì¶• ë°©ë²•

- êµ¬ì¶• í™˜ê²½
    - MacOS(Catalina 10.15.5)
    - AWS EC2
        - t2.small(3EA)
    - Red Hat Enterprise Linux 8
    - SSD 30GB

## AWS EC2 ì¸ìŠ¤í„´ìŠ¤ ìƒì„±

1. AWSì—ì„œ ê³„ì •ì„ ìƒì„±í•˜ê³  ë¡œê·¸ì¸ í•œ í›„, AWS Management Console - ì»´í“¨íŒ… - EC2ì— ì ‘ê·¼í•œë‹¤.

2. ì¸ìŠ¤í„´ìŠ¤ ì‹œì‘ì„ ëˆŒëŸ¬, ë‹¤ìŒ ìˆœì„œëŒ€ë¡œ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•œë‹¤.

    - AMI ì„ íƒ

    ![Amazon Machine Image](https://user-images.githubusercontent.com/60086878/96366595-74a09100-1183-11eb-808b-88dfd2f21adb.png)
    Red Hat Enterprise Linux 8
    
    - ì¸ìŠ¤í„´ìŠ¤ ìœ í˜• ì„ íƒ
    
    ![AWS On-Demand Pricing](https://user-images.githubusercontent.com/60086878/96366700-2e97fd00-1184-11eb-8e1c-7e5d011c7a98.png)
        - ìš”ê¸ˆì´ t2.microì˜ ê²¨ìš° 2ë°° ìˆ˜ì¤€ì¸ t2.small
        - AWSì˜ ì‚´ì¸ì ì¸ ìš”ê¸ˆì œì— í”„ë¦¬í‹°ì–´ ê³¼ê¸ˆì„ í”¼í•˜ê¸° ìœ„í•˜ì—¬ ì¸ìŠ¤í„´ìŠ¤ ìœ í˜•ì€ í”„ë¦¬í‹°ì–´ê¸‰ë³´ë‹¤ í•œ ë‹¨ê³„ ìƒìœ„ë²„ì „ì¸ t2.smallë¡œ ì§„í–‰
    
    - ì¸ìŠ¤í„´ìŠ¤ êµ¬ì„±
    1ê°œë¡œ êµ¬ì„±í•˜ì—¬ í•˜ë‘¡ì— í•„ìš”í•œ ì„¤ì •ì„ ëª¨ë‘ ë§ˆì¹œ í›„ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ì—¬ ë‚˜ë¨¸ì§€ 2ê°œë¥¼ ë§Œë“¤ ì˜ˆì •

    - ìŠ¤í† ë¦¬ì§€ ì¶”ê°€
    30 GB

    - ê²€í† 
    
        - AWS EC2ë¥¼ ì²˜ìŒ ì´ìš©í•  ê²½ìš°, ìƒˆ í‚¤ í˜ì–´ ìƒì„±ìœ¼ë¡œ í‚¤ í˜ì–´ ì´ë¦„ì„ ì…ë ¥í•œ í›„ í‚¤ í˜ì–´ ë‹¤ìš´ë¡œë“œ

        - ê¸°ì¡´ ìœ ì €ì˜ ê²½ìš°, ê¸°ì¡´ í‚¤ í˜ì–´ ì„ íƒ í›„ ì„ íƒí•œ í‚¤ íŒŒì¼ì— ì—‘ì„¸ìŠ¤ ê°€ëŠ¥ ì—¬ë¶€ ì²´í¬

3. ì¸ìŠ¤í„´ìŠ¤ ì ‘ì† 


![IPv4 Public IP](https://user-images.githubusercontent.com/60086878/96367212-5f2d6600-1187-11eb-8267-241a050a9571.png)


- í•´ë‹¹ ì¸ìŠ¤í„´ìŠ¤ì˜ Public IPë¥¼ ë³µì‚¬í•˜ê³ , í„°ë¯¸ë„ì—ì„œ ssh ëª…ë ¹ì–´ë¥¼ í†µí•´ ì ‘ì†í•œë‹¤.

```
$ ssh -i ./YOUR_KEY.pem ec2-user@PUBLIC_IP
```

![SSH Access](https://user-images.githubusercontent.com/60086878/96367234-7d936180-1187-11eb-8583-473b718bcc44.png)


## ë¦¬ëˆ…ìŠ¤ í™˜ê²½ì„¤ì •
1. SELINUX ë„ê¸°


ì›í™œí•œ ì„¤ì¹˜ë¥¼ ìœ„í•´ Red Hat ë³´ì•ˆ ìš”ì†Œì¸ SELINUXë¥¼ ë„ê³  ì§„í–‰
- etc íŒŒì¼ ìˆ˜ì •ì„ ìœ„í•´ sudo ëª…ë ¹ì–´ë¡œ config íŒŒì¼ ì—´ê¸°
```
$ sudo vi /etc/selinux/config
```

- SELINUX disabled

```
SELINUX=disabled
```

- ë³€ê²½ì‚¬í•­ ì ìš©ì„ ìœ„í•´ ì¬ë¶€íŒ…
```
$ sudo reboot
```

2. ë³´ì•ˆìƒ ìƒˆë¡œìš´ ê³„ì •ì„ ìƒì„±

- hadoop ì´ë¦„ìœ¼ë¡œ ìƒˆë¡œìš´ ê³„ì • ìƒì„±
```
$ useradd hadoop
```

- ë¹„ë°€ë²ˆí˜¸ ì„¤ì •
```
$ passwd hadoop
```

3. hadoop ê³„ì •ì— sudo ê¶Œí•œ ë¶€ì—¬

- etc íŒŒì¼ ìˆ˜ì •ì„ ìœ„í•´ sudo ëª…ë ¹ì–´ì™€ ì“°ê¸° ê¶Œí•œì—†ì´ ë°”ë¡œ í¸ì§‘í•  ìˆ˜ ìˆëŠ” visud ëª…ë ¹ì–´ë¥¼ í†µí•´ sudoersíŒŒì¼ ì—´ê¸°
```
$ sudo visudo /etc/sudoers
```

- ê³„ì •ê¶Œí•œ ë¶€ì—¬ ëª…ë ¹ ì¶”ê°€
```
hadoop  ALL=(ALL)   ALL
```
![Add Permission](https://user-images.githubusercontent.com/60086878/96367971-e67cd880-118b-11eb-80ed-635a50aab6ef.png)

4. SSH Key-based ì¸ì¦ ì„¤ì •


 ê³µê°œí‚¤ë¥¼ ë“±ë¡í•˜ì—¬ ê° ì¸ìŠ¤í„´ìŠ¤ë¼ë¦¬ ë¹„ë°€ë²ˆí˜¸ ì—†ì´ ì§€ì†ì ì¸ í†µì‹ ì„ ê°€ëŠ¥í•˜ê²Œ í•¨
- hadoop ê³„ì • ë¡œê·¸ì¸
```
$ su hadoop
```

- SSH Key ìƒì„± (ëª…ë ¹ì–´ ì‹¤í–‰ í›„ ì—”í„°)
```
$ ssh-keygen -t rsa
```

- authorized_keysíŒŒì¼ì— ê³µê°œí‚¤ ì¶”ê°€
```
$ cat ~/.ssh/id_rsa.pub >> ~/.ssh authorized_keys
```

- authorized_keys ê¶Œí•œ ë¶€ì—¬
```
$ chmod 640 ~/.ssh/authorized_keys
```

- ssh ì ‘ì† í™•ì¸
```
$ ssh localhost
```

## Hadoop ì„¤ì¹˜
1. Java ì„¤ì¹˜


 Hadoopì€ Javaë¡œ ì“°ì—¬ì§„ ì˜¤í”ˆ ì†ŒìŠ¤ì´ë¯€ë¡œ ì‚¬ì „ì— Java ì„¤ì¹˜ í•„ìˆ˜ì´ë‹¤. ë”°ë¼ì„œ Java ë²„ì „ì— ì˜í–¥ì„ ë§ì´ ë°›ìœ¼ë¯€ë¡œ, Hadoop 3.2.1 ë²„ì „ê³¼ í˜¸í™˜ë˜ëŠ” java-1.8.0-openjdk ë²„ì „ ì„¤ì¹˜í•œë‹¤.

- Java ì„¤ì¹˜
```
$ sudo dnf install java-1.8.0-openjdk ant -y
```

- Java ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜ì—¬ë¶€ í™•ì¸
```
$ java -version
```

2. Hadoop ì„¤ì¹˜


 [Hadoop 3.2.1](https://downloads.apache.org/hadoop/common/hadoop-3.2.1/hadoop-3.2.1.tar.gz) í•´ë‹¹ ë§í¬ë¥¼ ë³µì‚¬í•˜ì—¬ ì„¤ì¹˜
- ì›¹ íŒŒì¼ ë‹¤ìš´ë¡œë“œ íŒ¨í‚¤ì§€ ë‹¤ìš´ë¡œë“œ
```
$ sudo yum install wget
```

- Hadoop ì„¤ì¹˜

```
$ cd ~
$ sudo wget https://downloads.apache.org/hadoop/common/hadoop-3.2.1/hadoop-3.2.1.tar.gz
$ tar -xvzf hadoop-3.2.1.tar.gz
```

- í´ë”ëª… ë³€ê²½
```
$ mv hadoop-3.2.1 hadoop
```

- í™˜ê²½ë³€ìˆ˜ ì„¤ì •
```
$ vi ~/.bashrc
```

- í™˜ê²½ë³€ìˆ˜ ë‚´ìš© ì¶”ê°€


[Hadoop Cluster ì„¤ì • ê´€ë ¨ ë©”ë‰´ì–¼](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/ClusterSetup.html)

```
export JAVA_HOME=/usr/lib/jvm/jre-1.8.0-openjdk-1.8.0.265.b01-0.el8_2.x86_64
export HADOOP_HOME=/home/hadoop/hadoop
export HADOOP_INSTALL=$HADOOP_HOME
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export HADOOP_YARN_HOME=$HADOOP_HOME
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin
export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib/native"
```
JAVA_HOMEì€ /usr/lib/jvm/ ë°‘ì— í´ë”ëª…ìœ¼ë¡œ ì„¤ì •(ë‹¤ìš´ë¡œë“œ ì‹œê¸°ì— ë”°ë¼ ë¹Œë“œ ë²„ì „ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)

- í•˜ë‘¡ í™˜ê²½íŒŒì¼ ìˆ˜ì •
```
$ cd ~/hadoop/etc/hadoop
```

- workers ()
```
datanode1
datanode2
```

- core-site.xml
```
<configuration>
 <property>
  <name>fs.defaultFS</name>
   <value>hdfs://namenode:8020/</value>
 </property>
 <property>
  <name>io.file.buffer.size</name>
   <value>131072</value>
 </property>
</configuration>
```

- hdfs-site.xml
```
<configuration>
	<property>
		<name>dfs.replication</name>
		<value>1</value>
	</property>
	<property>
		<name>dfs.namenode.http-address</name>
		<value>namenode:50070</value>
	</property>
	<property>
		<name>dfs.namenode.secondary.http-address</name>
		<value>secondnode:50090</value>
	</property>
	<property>
		<name>dfs.datanode.http-address</name>
		<value>0.0.0.0:50010</value>
	</property>
	<property>
		<name>dfs.namenode.name.dir</name>
		<value>file:///home/hadoop/hadoop/data/name1,file:///home/hadoop/hadoop/data/name2</value>
	</property>
	<property>
		<name>dfs.datanode.data.dir</name>
		<value>file:///home/hadoop/hadoop/data</value>
	</property>
	<property>
		<name>dfs.namenode.checkpoint.dir</name>
		<value>file:///home/hadoop/hadoop/data/namesecondary</value>
	</property>
</configuration>
```

- mapred-site.xml
```
<configuration>
        <property>
                <name>mapreduce.framework.name</name>
                <value>yarn</value>
        </property>
        <property>
                <name>mapreduce.jobhistory.address</name>
                <value>namenode:10020</value>
        </property>
        <property>
                <name>mapreduce.jobhistory.webapp.address</name>
                <value>namenode:19888</value>
        </property>
        <property>
                <name>yarn.app.mapreduce.am.env</name>
                <value>HADOOP_MAPRED_HOME=${HADOOP_HOME}</value>
        </property>
        <property>
                <name>mapreduce.map.env</name>
                <value>HADOOP_MAPRED_HOME=${HADOOP_HOME}</value>
        </property>
        <property>
                <name>mapreduce.reduce.env</name>
                <value>HADOOP_MAPRED_HOME=${HADOOP_HOME}</value>
        </property>
</configuration>
```

- yarn-site.xml
```
<configuration>

<!-- Site specific YARN configuration properties -->
	<property>
		<name>yarn.resourcemanager.hostname</name>
		<value>secondnode</value>
	</property>
	<property>
		<name>yarn.nodemanager.local-dirs</name>
		<value>/home/hadoop/hadoop/data/nm</value>
	</property>
	<property>
		<name>yarn.nodemanager.aux-services</name>
		<value>mapreduce_shuffle</value>
	</property>
	<property>
		<name>yarn.nodemanager.resource.cpu-vcores</name>
		<value>2</value>
	</property>
</configuration>
```

- hdfs ì €ì¥ì„ ìœ„í•œ ë””ë ‰í† ë¦¬ ìƒì„±
```
$ cd hadoop
$ mkdir data
```

- ì¢…ë£Œ
```
$ sudo shutdown -h now
```

## ì´ë¯¸ì§€ ìƒì„± ë° ë³µì‚¬
1. ì´ë¯¸ì§€ ë³µì‚¬
- ì¸ìŠ¤í„´ìŠ¤ ëª©ë¡ì—ì„œ í•´ë‹¹ ì¸ìŠ¤í„´ìŠ¤ ì„ íƒ í›„ ë³µì‚¬
![Create AMI](https://user-images.githubusercontent.com/60086878/96369153-55a9fb00-1193-11eb-865d-5a4c82677af9.png)

2. AMI ìƒì„±
- AMI ëª©ë¡ì—ì„œ í•´ë‹¹ ì´ë¯¸ì§€ ìƒì„± (ë‚˜ë¨¸ì§€ êµ¬ì„±ì€ ë™ì¼í•˜ê²Œ í•˜ë˜, ì¸ìŠ¤í„´ìŠ¤ êµ¬ì„±ì€ 2ê°œë¡œ ì§„í–‰)

- ì¸ìŠ¤í„´ìŠ¤ ëª©ë¡ì—ì„œ ê° ì¸ìŠ¤í„´ìŠ¤ë¥¼ êµ¬ë¶„í•˜ê¸° ì‰½ê²Œ, ì¸ìŠ¤í„´ìŠ¤ ì´ë¦„ì„ ê°ê° Client, Namenode, Secondnodeë¡œ ìˆ˜ì •
![Set Name](https://user-images.githubusercontent.com/60086878/96369527-7ecb8b00-1195-11eb-9a89-483cc5396bac.png)

- ì´ì „ê³¼ ë™ì¼í•œ ë°©ë²•ìœ¼ë¡œ 3ê°œì˜ í„°ë¯¸ë„ì—ì„œ ê°ê°ì˜ ì¸ìŠ¤í„´ìŠ¤ì— ì ‘ì† (ì¸ìŠ¤í„´ìŠ¤ëŠ” ì¬ë¶€íŒ… í›„ Public IPê°€ ì¬í• ë‹¹ë˜ë¯€ë¡œ ì¬í™•ì¸ í›„ ì ‘ì†)

3. hostname ì„¤ì •
- ê°ê°ì˜ ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ì§„í–‰
```
$ sudo hostnamectl set-hostname client
$ sudo hostnamectl set-hostname namenode
$ sudo hostnamectl set-hostname secondnode
```

4. ê°ê°ì˜ ì¸ìŠ¤í„´ìŠ¤ ì—°ê²°
- hosts íŒŒì¼ ì—´ê¸°
```
$ sudo vi /etc/hosts
```

- ê°ê°ì˜ Private IP ì—°ë™ (172.x.x.x)
```
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
172.31.28.51    client
172.31.18.187   namenode
172.31.18.187   datanode1
172.31.20.195   secondnode
172.31.20.195   datanode2
```
![Private IP](https://user-images.githubusercontent.com/60086878/96369633-2943ae00-1196-11eb-951f-b45c8d91a16f.png)

- SSH ì ‘ê·¼ í™•ì¸ (hadoop ê³„ì •ì—ì„œ ì‹¤í–‰)
```
$ ssh client
$ ssh secondnode
$ ssh namenode
```
ëª¨ë‘ ì´ìƒì—†ì´ ì—°ê²°ëœë‹¤ë©´ ê°ê°ì˜ ì¸ìŠ¤í„´ìŠ¤ê°€ ì„œë¡œ ì¸ì¦ì—†ì´ í†µì‹ í•  ìˆ˜ ìˆëŠ” ìƒíƒœë¥¼ ì˜ë¯¸

## Hadoop ì‹¤í–‰
1. Hadoop êµ¬ë™
- hdfs íŒŒì¼ í¬ë§·
```
$ hadoop namenode -format 
```

- dfs(namenode) ì‹œì‘
```
$ start-dfs.sh
$ jps
$ ssh secondnode
$ jps
```
namenodeì—ì„œëŠ” jps ëª…ë ¹ì–´ ì‹œ DataNode, NameNodeê°€ ì‹¤í–‰


secondnodeì—ì„œëŠ” jps ëª…ë ¹ì–´ ì‹œ DataNode, SecondaryNameNodeê°€ ì‹¤í–‰

- yarn(secondnode) ì‹œì‘
```
$ start-yarn.sh
$ jps
```
secondnodeì—ì„œ jps ëª…ë ¹ì–´ ì‹œ ì¶”ê°€ë¡œ ResourceManager, NodeManagerê°€ ì‹¤í–‰

2. Hadoop ëª¨ë‹ˆí„°ë§
ì™¸ë¶€ì—ì„œ ì¸ìŠ¤í„´ìŠ¤ì— ì ‘ì†í•  ìˆ˜ ìˆë„ë¡ ë°©í™”ë²½ ì„¤ì •ì„ í†µí•´ íŠ¹ì • IPì™€ í¬íŠ¸ë¥¼ ì„¤ì •í•˜ëŠ” ì‘ì—…ì´ í•„ìš”

- ë‚´ IP í™•ì¸
[ë‚´ IP ì£¼ì†Œ í™•ì¸](https://www.findip.kr)

- ë³´ì•ˆê·¸ë£¹ ì„¤ì • ì ‘ê·¼
![Security Group](https://user-images.githubusercontent.com/60086878/96371729-2baa0600-119e-11eb-8347-cc7c3548c1fb.png)


- ì¸ìŠ¤í„´ìŠ¤ì˜ ë³´ì•ˆê·¸ë£¹ íƒ­ìœ¼ë¡œ ì ‘ê·¼í•˜ì—¬ ê° ì¸ìŠ¤í„´ìŠ¤ì— í•´ë‹¹í•˜ëŠ” ë³´ì•ˆê·¸ë£¹ì˜ ì¸ë°”ìš´ë“œ ê·œì¹™ í¸ì§‘
![Setting Security Group](https://user-images.githubusercontent.com/60086878/96371898-12ee2000-119f-11eb-8782-ff4388e21825.png)


ì†ŒìŠ¤ëŠ” ê°ì ë³¸ì¸ IP ì£¼ì†Œ/32(eg; 111.222.333.4/32)

- namenode Public IP:50070
- secondnode Public IP:8088
![Manage Page](https://user-images.githubusercontent.com/60086878/96372012-d53dc700-119f-11eb-8dff-a1dd1c25c075.png)

# ì°¸ê³ 
- ì—”í„°í”„ë¼ì´ì¦ˆ ë°ì´í„° í”Œë«í¼ êµ¬ì¶• (ì±…ë§Œ)
- [ë°ì´í„°ì‹¤ë¬´ ê¸°ìˆ  ê°€ì´ë“œ > ë°ì´í„° ì²˜ë¦¬](http://www.dbguide.net/db.db?cmd=view&boardUid=187336&boardConfigUid=9&categoryUid=1459&boardIdx=158&boardStep=1) (DBGuide)
- [How To Install and Configure Hadoop on CentOS/RHEL 8](https://tecadmin.net/install-hadoop-centos-8/)